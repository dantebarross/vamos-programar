{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 O classificador Naive Bayes\n",
    "O algoritmo **Naive Bayes** é um classificador probabilístico simples, que aplica o **teorema de Bayes** e que supõe **independência entre os preditores**. Isso significa que, caso seja constatada a presença de um elemento dentro de uma classe, **esse elemento não possui relação alguma com os outros elementos da mesma classe**. Vamos a um exemplo.\n",
    "\n",
    "Imagine uma laranja:\n",
    "1. quão laranja ela é?\n",
    "2. quão dura é sua casca?\n",
    "3. quão grande ela é?\n",
    "4. quão redonda ela é?\n",
    "\n",
    "Mesmo que essas quatro características juntas possuem o poder de definir uma laranja, eles contribuem de forma independente para a probabilidade dessa fruta ser uma laranja. É por conta dessa \"injenuidade\" que o classificador se chama **Naive Bayes** (literalmente, **Bayes Ingênuo**). Ele compartilha diversas similariedades com o método de Regressão Logística\n",
    "\n",
    "Você pode ter duvidado que ele seja realmente eficaz. Acredite, ele é **simples**, **fácil de construir** e **muito útil**. Chega a ser melhor do que muitos outros algoritmos de classificação. \n",
    "\n",
    "É por esses motivos que vamos estudá-lo e utilizá-lo em nosso sistema de **análise automática de sentimento**.\n",
    "\n",
    "### 2.2.1 Aplicando o classificador em Análise do Sentimento\n",
    "#### Vamos novamente utilizar o **corpus de tweets** do NLTK, que está separado em \"Tweets **Positivos**\" e \"Tweets **Negativos**\";\n",
    "1. Precisamos contar **quantas vezes** cada palavra aparece em cada um desses _sets_;\n",
    "2. Então será necessário calcular a **probabilidade condicional** de cada palavra dos conjuntos;\n",
    "3. Incluir o **valor** de todas as probabilidades em uma nova tabela;\n",
    "4. Somar os valores de cada uma das duas colunas e **perceber como a soma resultou no número \"1\"*.\n",
    "\n",
    "<img src=\"images/naive bayes tabela probabilidade.png\" width=60%>\n",
    "\n",
    "#### Por fim, se seguirmos as instruções, obteremos a **tabela de probabilidades** abaixo:\n",
    "<img src=\"images/naive bayes tabela probabilidade2.png\" width=25%>\n",
    "\n",
    "Repare nos valores da coluna **Pos** e da coluna **Neg**, pois ambos possuem uma **probabilidade condicional** muito próxima ou até mesmo idêntica. Vamos listar quais são essas palavras:\n",
    "* I\n",
    "* am\n",
    "* learning\n",
    "* NLP\n",
    "\n",
    "Viu como essas são exatamente as **palavras que não adicionam qualquer tipo de significado sentimental** para seus tweets? Agora perceba como as outras palavras possuem (com razão) uma **probabilidade maior ou menor**, a depender da classificação de seu tweet original.\n",
    "\n",
    "Temos um problema em nosso _dataset_. É a palavra **because**. Ela possui **probabilidade zero** em 'Neg', portanto não possui probabilidade alguma de ocorrer em tweets negativos. Isso aconteceu pois, por diversos fatores no colhimento dos dados (e **azar** pode ser um deles), não possuímos nenhum tweet Negativo que contenha a palavra 'because'.\n",
    "\n",
    "Para resolver esse problema, temos que **manipular** esse dado, **suavizando-o**.\n",
    "\n",
    "### 2.2.2 Classificação binária com Naive Bayes\n",
    "Quando recebermos **um novo input de tweet**, podemos facilmente calcular a probabilidade de este ser Positivo ou Negativo. Como estas duas classes são **binárias** (bom/ruim, ligado/desligado, alto/baixo, etc), vamos utilizar a expressão abaixo:\n",
    "\n",
    "<img src=\"images/naive bayes inference condition rule.png\" width=20%>\n",
    "\n",
    "A expressão diz respeito à **Naive Bayes Inference Condition Rule for binary classification**. Que nome grande não? Rsrs. Vamos chamar apenas de **classificação binária** (binary classification) utilizando Naive Bayes. Essa expressão nos diz isso:\n",
    "1. Em $P(w_i|pos)$, você deve trazer o **produto** (w) da **probabilidade** (P) de **cada palavra** (i) da coluna **Pos** (pos);\n",
    "2. e então **dividir** por $P(w_i|neg)$, que é o produto da probabilidade de cada palavra da coluna **Neg**\n",
    "\n",
    "Não sabe o que é um **produto**? É simplesmente **o resultado da aplicação do operador de multiplicação**.\n",
    "\n",
    "Vamos calcular e classificar a frase \"I am happy today; I am learning\", baseado nos dados da tabela abaixo:\n",
    "\n",
    "<img src=\"images/naive bayes tabela probabilidade3.png\" width=25%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pegue os valores das probabilidades (Pos e Neg) de cada palavra (se ela existir no vocabulário), multiplique-os e assim obtenha o **produto** dos valores de **Pos** e **Neg**. Agora é só dividir um pelo outro!\n",
    "\n",
    "| Tweet | I | am | happy | I | am | learning |\n",
    "| :-: | :-: | :-: | :-: | :-: | :-: | :-: |\n",
    "| 'Pos'| 0.20|0.20|0.14|0.20|0.20|0.10|\n",
    "| 'Neg'|0.20|0.20|0.10|0.20|0.20|0.10|\n",
    "\n",
    "Podemos então **riscar as palavras neutras**, ou seja, aquelas que a probabilidade de ser 'Pos' e 'Neg' é **idêntica**. Por fim, só nos resta a palavra **happy**. Vamos **dividir as probabilidades** e chegar ao resultado final dessa expressão.\n",
    "\n",
    "$\\dfrac {0.14}{0.10} = 1.4 $\n",
    "\n",
    "Chegamos a conclusão de que **o novo tweet** é classificado como '**Positive**', pois sua **classificação binária** utilizando as **probabilidades** obtidas pelo método **Naive Bayes**:\n",
    "1. resultou em um valor **maior que 1** (1.4);\n",
    "2. é portanto '**Positive**'.\n",
    "\n",
    "Prontinho! \n",
    "- Acabamos de criar uma **tabela** para inserir os valores das **probabilidades condicionais** de cada palavra do nosso vocabulário, separadas entre tweets Positivos e Negativos.\n",
    "- Depois aplicamos a **classificação binária Naive Bayes** para classificar um tweet nunca antes visto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
