{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output:\n",
    "- J: the final cost / cost function\n",
    "- theta: your final weight vector\n",
    "\n",
    "Calcular... **for i in range(0, num_iters):**\n",
    "- m = number of rows in matrix x/training examples\n",
    "- z = the dot product of x and theta (n+1, 1)\n",
    "    - The 'logits', 'z', are calculated by multiplying the feature matrix 'x' with the weight vector 'theta'.  𝑧=𝐱𝜃\n",
    "- h = the sigmoid of z (m, 1)\n",
    "    - calculated by applying the sigmoid to each element in 'z':  ℎ(𝑧)=𝑠𝑖𝑔𝑚𝑜𝑖𝑑(𝑧).\n",
    "- theta = update the weights theta (vector is (n+1, 1)) 'n' is the number of features, and the other element is the 'bias'\n",
    "- 𝐽 = the cost function:\n",
    "    - is calculated by taking the dot product of the vectors 'y' and 'log(h)'. Since both 'y' and 'h' are column vectors (m,1), transpose the vector to the left, so that matrix multiplication of a row vector with column vector performs the dot product.\n",
    "    \n",
    "$$J = \\frac{-1}{m} \\times \\left(\\mathbf{y}^T \\cdot log(\\mathbf{h}) + \\mathbf{(1-y)}^T \\cdot log(\\mathbf{1-h}) \\right)$$\n",
    "\n",
    "- The update of theta is also vectorized.  Because the dimensions of $\\mathbf{x}$ are (m, n+1), and both $\\mathbf{h}$ and $\\mathbf{y}$ are (m, 1), we need to transpose the $\\mathbf{x}$ and place it on the left in order to perform matrix multiplication, which then yields the (n+1, 1) answer we need:\n",
    "$$\\mathbf{\\theta} = \\mathbf{\\theta} - \\frac{\\alpha}{m} \\times \\left( \\mathbf{x}^T \\cdot \\left( \\mathbf{h-y} \\right) \\right)$$\n",
    "\n",
    "Etc...\n",
    "- x: matrix of features which is (m,n+1)\n",
    "- y: corresponding labels of the input matrix x, dimensions (m,1)\n",
    "- alpha: learning rate\n",
    "- num_iters: number of iterations you want to train your model for\n",
    "- use np.dot for matrix multiplication.\n",
    "- To ensure that the fraction -1/m is a decimal value, cast either the numerator or denominator (or both), like `float(1)`, or write `1.` for the float version of 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
