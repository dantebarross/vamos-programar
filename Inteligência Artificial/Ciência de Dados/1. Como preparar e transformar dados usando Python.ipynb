{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Como preparar e transformar dados usando Python\n",
    "\n",
    "**Vamos mostrar nessa aula o que fazer ao receber um banco de dados _sujo_**:\n",
    "- A remo√ß√£o de linhas que contenham o dado;  \n",
    "- A altera√ß√£o dos dados espec√≠ficos utilizando um n√∫mero m√©dio que n√£o afete a an√°lise.\n",
    "\n",
    "**Tamb√©m vamos aprender como Normalizar e Padronizar os dados**:\n",
    "- Normaliza√ß√£o e Padroniza√ß√£o de dados\n",
    "<a name=\"intro\"></a>\n",
    
    "### Sum√°rio\n",
    "1. [Removendo dados estranhos](#git1)\n",
    "2. [Substituindo valores](#git2)\n",
    "3. [Normaliza√ß√£o e Padroniza√ß√£o de dados](#git3)\n",
    "    1. [Normaliza√ß√£o](#git3.1)\n",
    "    2. [Padroniza√ß√£o](#git3.2)\n",
    "4. [Binariza√ß√£o dos dados](#git4)\n",
    "5. [Transformando vari√°veis nominais em n√∫meros inteiros](#git5)\n",
    "6. [One-hot encoding: transformando valores em c√≥digos bin√°rios](#git6)\n",
    "7. [Correlacionando dados](#git7)\n",
    "8. [Dados desbalanceados: como detectar, analisar e balancear](#git8)\n",
    "9. [An√°lise de Componentes Principais (PCA)](#git9)\n",
    "10. [Boxplot: detectando, exibindo e descartando _outliers_](#git10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao receber um conjunto de dados, provavelmente podem ser encontrados erros, inconsist√™ncias e informa√ß√µes dobradas. Antes de realizar qualquer an√°lise estat√≠stica ou aplica√ß√£o de algoritmos, devemos realizar uma limpeza na base de dados colhida.\n",
    "\n",
    "Para a leitura e manipula√ß√£o de tabelas, utilizaremos a biblioteca _pandas_, que pode ser facilmente instalada atrav√©s do comando _pip install pandas_.\n",
    "\n",
    "O banco de dados ser√° o arquivo CSV (que pode ser aberto tamb√©m no Excel e em outros leitores de planilha).\n",
    "\n",
    "Tamb√©m utilizaremos a biblioteca matplotlib, uma das mais utilizadas para visualizar os dados por meio de gr√°ficos.\n",
    "Vamos importar as bibliotecas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Removendo dados estranhos <a name=\"git1\"></a> [ü†°](#intro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos associar os dados \"iris-with-errors.csv\" √† vari√°vel _data_, chamar o _print_ contendo o n√∫mero de linhas e colunas atrav√©s do comando shape e exibir as 25 primeiras linhas (incluindo o cabe√ßalho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linha, coluna: (25, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>duplicada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>duplicada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>duplicada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>duplicada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>duplicada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>duplicada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>duplicada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>duplicada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>?</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.7</td>\n",
       "      <td>?</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length sepal_width  petal_length petal_width    species\n",
       "0           5.1         3.5           1.4         0.2  duplicada\n",
       "1           5.1         3.5           1.4         0.2  duplicada\n",
       "2             ?           3           1.4         0.2     setosa\n",
       "3           4.7         3.2           1.3         0.2     setosa\n",
       "4           5.1         3.5           1.4         0.2  duplicada\n",
       "5           NaN         3.1           1.5         0.2     setosa\n",
       "6             5         3.6           1.4         0.2     setosa\n",
       "7           5.4         3.9           1.7         0.4  duplicada\n",
       "8           5.4         3.9           1.7         0.4  duplicada\n",
       "9           4.6         3.4           1.4         NaN     setosa\n",
       "10            5         3.4           1.5         0.2     setosa\n",
       "11          4.4         2.9           1.4         0.2  duplicada\n",
       "12          4.9         3.1           1.5         0.1     setosa\n",
       "13          5.4         3.7           1.5         0.2     setosa\n",
       "14          4.4         2.9           1.4         0.2  duplicada\n",
       "15          4.8         3.4           1.6         0.2     setosa\n",
       "16          4.8           3           1.4         0.1     setosa\n",
       "17          4.4         2.9           1.4         0.2  duplicada\n",
       "18          4.3           3           1.1         0.1     setosa\n",
       "19          5.8           4           1.2         0.2     setosa\n",
       "20          5.7         4.4           1.5         0.4     setosa\n",
       "21          5.4         3.9           1.3           ?     setosa\n",
       "22          5.1         3.5           1.4         0.3     setosa\n",
       "23          5.7           ?           1.7         0.3     setosa\n",
       "24          NaN         3.8           1.5         0.3     setosa"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('dados/iris-with-errors.csv', header=(0))\n",
    "print(\"Linha, coluna:\", data.shape)\n",
    "data.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver alguns erros:\n",
    "1. O caractere \"?\"\n",
    "2. A express√£o _NaN_, quando o computador n√£o sabe de que tipo √© a informa√ß√£o\n",
    "3. Na coluna _species_, s√£o indicadas se as linhas s√£o duplicadas\n",
    "\n",
    "Precisamos rever os dados ou descart√°-los. Aqui, vamos escolher a segunda op√ß√£o e utilizar o pandas para isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     False\n",
       "1      True\n",
       "2     False\n",
       "3     False\n",
       "4      True\n",
       "6     False\n",
       "7     False\n",
       "8      True\n",
       "10    False\n",
       "11    False\n",
       "12    False\n",
       "13    False\n",
       "14     True\n",
       "15    False\n",
       "16    False\n",
       "17     True\n",
       "18    False\n",
       "19    False\n",
       "20    False\n",
       "21    False\n",
       "22    False\n",
       "23    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna() # Remove os dados NaN\n",
    "data.duplicated() # Verifica se h√° dados duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos perceber no _Output_ acima que as linhas duplicadas receberam o estado **True**. De duas linhas iguais, somente a que vem depois da primeira √© a \"duplicada\". Vamos descartar essas linhas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>duplicada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>duplicada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>duplicada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>?</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.7</td>\n",
       "      <td>?</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length sepal_width  petal_length petal_width    species\n",
       "0           5.1         3.5           1.4         0.2  duplicada\n",
       "2             ?           3           1.4         0.2     setosa\n",
       "3           4.7         3.2           1.3         0.2     setosa\n",
       "6             5         3.6           1.4         0.2     setosa\n",
       "7           5.4         3.9           1.7         0.4  duplicada\n",
       "10            5         3.4           1.5         0.2     setosa\n",
       "11          4.4         2.9           1.4         0.2  duplicada\n",
       "12          4.9         3.1           1.5         0.1     setosa\n",
       "13          5.4         3.7           1.5         0.2     setosa\n",
       "15          4.8         3.4           1.6         0.2     setosa\n",
       "16          4.8           3           1.4         0.1     setosa\n",
       "18          4.3           3           1.1         0.1     setosa\n",
       "19          5.8           4           1.2         0.2     setosa\n",
       "20          5.7         4.4           1.5         0.4     setosa\n",
       "21          5.4         3.9           1.3           ?     setosa\n",
       "22          5.1         3.5           1.4         0.3     setosa\n",
       "23          5.7           ?           1.7         0.3     setosa"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop_duplicates()\n",
    "data.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora s√≥ falta removermos as interroga√ß√µes \"?\". Um dos modos de fazer isso √© transformar tal caractere em um _NaN_, e logo em seguida limpar novamente as linhas que contenham _NaN_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>duplicada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>duplicada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>duplicada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length sepal_width  petal_length petal_width    species\n",
       "0           5.1         3.5           1.4         0.2  duplicada\n",
       "3           4.7         3.2           1.3         0.2     setosa\n",
       "6             5         3.6           1.4         0.2     setosa\n",
       "7           5.4         3.9           1.7         0.4  duplicada\n",
       "10            5         3.4           1.5         0.2     setosa\n",
       "11          4.4         2.9           1.4         0.2  duplicada\n",
       "12          4.9         3.1           1.5         0.1     setosa\n",
       "13          5.4         3.7           1.5         0.2     setosa\n",
       "15          4.8         3.4           1.6         0.2     setosa\n",
       "16          4.8           3           1.4         0.1     setosa\n",
       "18          4.3           3           1.1         0.1     setosa\n",
       "19          5.8           4           1.2         0.2     setosa\n",
       "20          5.7         4.4           1.5         0.4     setosa\n",
       "22          5.1         3.5           1.4         0.3     setosa"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = data.replace('?', np.nan) # Usa o comando replace para substituir as interroga√ß√µes em NaN's\n",
    "data = data.dropna() # Remove as linhas que contenham NaN\n",
    "data.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os dados limpos, n√£o precisamos mais das classifica√ß√µes da coluna **species**, certo? Vamos remove-la!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vamos remover a coluna: species\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sepal_length sepal_width  petal_length petal_width\n",
       "0          5.1         3.5           1.4         0.2\n",
       "3          4.7         3.2           1.3         0.2"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Vamos remover a coluna:\", data.columns[4]) # Para exibir as colunas que ser√£o removidas, use o comando .columns\n",
    "data = data.drop(data.columns[4], axis=1) # Nesse comando, precisamos indicar o axis=1 que significa coluna\n",
    "data.head(2) # Pra verificarmos se a coluna foi removida, podemos visualizar apenas poucas linhas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso mais algum dado distoe e voc√™ queira remover diretamente uma linha escolhida, podemos utilizar o comando acima com a indica√ß√£o **axis=0** indicando o n√∫mero e o tipo linha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vamos remover as linhas: Int64Index([0, 6], dtype='int64')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length sepal_width  petal_length petal_width\n",
       "3           4.7         3.2           1.3         0.2\n",
       "7           5.4         3.9           1.7         0.4\n",
       "10            5         3.4           1.5         0.2\n",
       "11          4.4         2.9           1.4         0.2\n",
       "12          4.9         3.1           1.5         0.1\n",
       "13          5.4         3.7           1.5         0.2\n",
       "15          4.8         3.4           1.6         0.2\n",
       "16          4.8           3           1.4         0.1\n",
       "18          4.3           3           1.1         0.1\n",
       "19          5.8           4           1.2         0.2\n",
       "20          5.7         4.4           1.5         0.4\n",
       "22          5.1         3.5           1.4         0.3"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Vamos remover as linhas:\", data.index[[0, 2]]) # Para exibir as linhas que ser√£o removidas, use o comando .index\n",
    "data = data.drop(data.index[[0, 2]], axis=0)\n",
    "data.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pronto! Removemos as linhas _[0, 2]_, ou seja, a primeira e a terceira linha, de n√∫mero **0** e **6**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Substituindo valores <a name=\"git2\"></a> [ü†°](#intro)\n",
    " \n",
    "Se forem constatados valores ausentes, podemos substitui-los facilmente. Vamos utilizar agora a vari√°vel _data_ausente_, relacionada aos mesmos dados iniciais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>duplicada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>duplicada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>duplicada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>duplicada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>duplicada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>duplicada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>duplicada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>duplicada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>?</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.7</td>\n",
       "      <td>?</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length sepal_width  petal_length petal_width    species\n",
       "0           5.1         3.5           1.4         0.2  duplicada\n",
       "1           5.1         3.5           1.4         0.2  duplicada\n",
       "2             ?           3           1.4         0.2     setosa\n",
       "3           4.7         3.2           1.3         0.2     setosa\n",
       "4           5.1         3.5           1.4         0.2  duplicada\n",
       "5           NaN         3.1           1.5         0.2     setosa\n",
       "6             5         3.6           1.4         0.2     setosa\n",
       "7           5.4         3.9           1.7         0.4  duplicada\n",
       "8           5.4         3.9           1.7         0.4  duplicada\n",
       "9           4.6         3.4           1.4         NaN     setosa\n",
       "10            5         3.4           1.5         0.2     setosa\n",
       "11          4.4         2.9           1.4         0.2  duplicada\n",
       "12          4.9         3.1           1.5         0.1     setosa\n",
       "13          5.4         3.7           1.5         0.2     setosa\n",
       "14          4.4         2.9           1.4         0.2  duplicada\n",
       "15          4.8         3.4           1.6         0.2     setosa\n",
       "16          4.8           3           1.4         0.1     setosa\n",
       "17          4.4         2.9           1.4         0.2  duplicada\n",
       "18          4.3           3           1.1         0.1     setosa\n",
       "19          5.8           4           1.2         0.2     setosa\n",
       "20          5.7         4.4           1.5         0.4     setosa\n",
       "21          5.4         3.9           1.3           ?     setosa\n",
       "22          5.1         3.5           1.4         0.3     setosa\n",
       "23          5.7           ?           1.7         0.3     setosa\n",
       "24          NaN         3.8           1.5         0.3     setosa"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ausente = pd.read_csv('dados/iris-with-errors.csv', header=(0))\n",
    "print(data_ausente.shape) # N√∫mero de linhas e colunas, lembra?\n",
    "data_ausente.head(50) # Opa! Eu quero agora exibir 50 linhas, o que ser√° que vai acontecer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora n√≥s estamos com d√≥ de descartar os dados, pois a linha ainda possui informa√ß√µes us√°veis. Um jeito inteligente √© substituir os valores \"?\" e os \"NaN\", colocando no lugar um **valor m√©dio**, ou seja, o valor que seria mais prov√°vel naquele lugar. Essa op√ß√£o √© boa para esse caso, pois n√£o possu√≠mos muitas linhas de dados, e remov√™-las ocasionaria em menos informa√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1        3.5        1.4        0.2       ]\n",
      " [5.1        3.5        1.4        0.2       ]\n",
      " [5.02272727 3.         1.4        0.2       ]\n",
      " [4.7        3.2        1.3        0.2       ]\n",
      " [5.1        3.5        1.4        0.2       ]\n",
      " [5.02272727 3.1        1.5        0.2       ]\n",
      " [5.         3.6        1.4        0.2       ]\n",
      " [5.4        3.9        1.7        0.4       ]\n",
      " [5.4        3.9        1.7        0.4       ]\n",
      " [4.6        3.4        1.4        0.22608696]\n",
      " [5.         3.4        1.5        0.2       ]\n",
      " [4.4        2.9        1.4        0.2       ]\n",
      " [4.9        3.1        1.5        0.1       ]\n",
      " [5.4        3.7        1.5        0.2       ]\n",
      " [4.4        2.9        1.4        0.2       ]\n",
      " [4.8        3.4        1.6        0.2       ]\n",
      " [4.8        3.         1.4        0.1       ]\n",
      " [4.4        2.9        1.4        0.2       ]\n",
      " [4.3        3.         1.1        0.1       ]\n",
      " [5.8        4.         1.2        0.2       ]\n",
      " [5.7        4.4        1.5        0.4       ]\n",
      " [5.4        3.9        1.3        0.22608696]\n",
      " [5.1        3.5        1.4        0.3       ]\n",
      " [5.7        3.4375     1.7        0.3       ]\n",
      " [5.02272727 3.8        1.5        0.3       ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data_ausente = data_ausente.replace('?', np.nan) # Transformamos os \"?\" em NaN\n",
    "\n",
    "\n",
    "# Vamos usar o comando abaixo para transformar as linhas e colunas em formato Numpy (em Arrays)\n",
    "X = np.array(data_ausente[data_ausente.columns[0:data_ausente.shape[1]-1]], dtype = float) # Tamb√©m ignoramos a √∫ltima coluna\n",
    "\n",
    "averages = np.nanmean(X, axis = 0) # Usamos a fun√ß√£o nanmean que calcula a m√©dia (ou mediana em alguns casos) ignorando os Nan\n",
    "for i in np.arange(0, X.shape[0]):\n",
    "    for j in np.arange(0, X.shape[1]):\n",
    "        if(np.isnan(X[i,j]) == True): # Vamos verificar se √© um dado NaN\n",
    "            X[i,j] = averages[j] # Inserimos a m√©dia\n",
    "print(X) # Exibimos o Array que foi constru√≠do, calculado e alterado\n",
    "\n",
    "# Documenta√ß√£o - https://docs.scipy.org/doc/numpy/reference/generated/numpy.nanmean.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Normaliza√ß√£o e Padroniza√ß√£o de dados <a name=\"git3\"></a> [ü†°](#intro)\n",
    "#### 3.1 Normaliza√ß√£o <a name=\"git3.1\"></a> [ü†°](#intro)\n",
    "A **Normaliza√ß√£o** √© o m√©todo em que pegamos o maior dado da planilha e transformamos em **1**, e o menor em **0**. Os que estiverem entre eles ser√£o **normalizados**. Para isso vamos utilizar a biblioteca sklearn que j√° faz isso para n√≥s.\n",
    "\n",
    "Importamos o banco de dados _iris.csv_ e associamos √† vari√°vel _data_normalizada_, importamos as bibliotecas _numpy_ e _sklearn_. Transformamos a tabela em Array como da √∫ltima vez, ignorando a √∫ltima coluna.\n",
    "\n",
    "**Aten√ß√£o!!**: N√£o esque√ßa de instalar a nova biblioteca utilizando o comando _pip install sklearn_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAIOR valor da coluna 0 = 7.9\n",
      "MENOR Valor da coluna 0 = 4.3\n",
      "MAIOR valor da coluna 1 = 4.4\n",
      "MENOR Valor da coluna 1 = 2.0\n",
      "MAIOR valor da coluna 2 = 6.9\n",
      "MENOR Valor da coluna 2 = 1.0\n",
      "[[0.22222222 0.625      0.06779661]\n",
      " [0.16666667 0.41666667 0.06779661]\n",
      " [0.11111111 0.5        0.05084746]\n",
      " [0.08333333 0.45833333 0.08474576]\n",
      " [0.19444444 0.66666667 0.06779661]\n",
      " [0.30555556 0.79166667 0.11864407]\n",
      " [0.08333333 0.58333333 0.06779661]\n",
      " [0.19444444 0.58333333 0.08474576]\n",
      " [0.02777778 0.375      0.06779661]\n",
      " [0.16666667 0.45833333 0.08474576]\n",
      " [0.30555556 0.70833333 0.08474576]\n",
      " [0.13888889 0.58333333 0.10169492]\n",
      " [0.13888889 0.41666667 0.06779661]\n",
      " [0.         0.41666667 0.01694915]\n",
      " [0.41666667 0.83333333 0.03389831]\n",
      " [0.38888889 1.         0.08474576]\n",
      " [0.30555556 0.79166667 0.05084746]\n",
      " [0.22222222 0.625      0.06779661]\n",
      " [0.38888889 0.75       0.11864407]\n",
      " [0.22222222 0.75       0.08474576]\n",
      " [0.30555556 0.58333333 0.11864407]\n",
      " [0.22222222 0.70833333 0.08474576]\n",
      " [0.08333333 0.66666667 0.        ]\n",
      " [0.22222222 0.54166667 0.11864407]\n",
      " [0.13888889 0.58333333 0.15254237]\n",
      " [0.19444444 0.41666667 0.10169492]\n",
      " [0.19444444 0.58333333 0.10169492]\n",
      " [0.25       0.625      0.08474576]\n",
      " [0.25       0.58333333 0.06779661]\n",
      " [0.11111111 0.5        0.10169492]\n",
      " [0.13888889 0.45833333 0.10169492]\n",
      " [0.30555556 0.58333333 0.08474576]\n",
      " [0.25       0.875      0.08474576]\n",
      " [0.33333333 0.91666667 0.06779661]\n",
      " [0.16666667 0.45833333 0.08474576]\n",
      " [0.19444444 0.5        0.03389831]\n",
      " [0.33333333 0.625      0.05084746]\n",
      " [0.16666667 0.45833333 0.08474576]\n",
      " [0.02777778 0.41666667 0.05084746]\n",
      " [0.22222222 0.58333333 0.08474576]\n",
      " [0.19444444 0.625      0.05084746]\n",
      " [0.05555556 0.125      0.05084746]\n",
      " [0.02777778 0.5        0.05084746]\n",
      " [0.19444444 0.625      0.10169492]\n",
      " [0.22222222 0.75       0.15254237]\n",
      " [0.13888889 0.41666667 0.06779661]\n",
      " [0.22222222 0.75       0.10169492]\n",
      " [0.08333333 0.5        0.06779661]\n",
      " [0.27777778 0.70833333 0.08474576]\n",
      " [0.19444444 0.54166667 0.06779661]\n",
      " [0.75       0.5        0.62711864]\n",
      " [0.58333333 0.5        0.59322034]\n",
      " [0.72222222 0.45833333 0.66101695]\n",
      " [0.33333333 0.125      0.50847458]\n",
      " [0.61111111 0.33333333 0.61016949]\n",
      " [0.38888889 0.33333333 0.59322034]\n",
      " [0.55555556 0.54166667 0.62711864]\n",
      " [0.16666667 0.16666667 0.38983051]\n",
      " [0.63888889 0.375      0.61016949]\n",
      " [0.25       0.29166667 0.49152542]\n",
      " [0.19444444 0.         0.42372881]\n",
      " [0.44444444 0.41666667 0.54237288]\n",
      " [0.47222222 0.08333333 0.50847458]\n",
      " [0.5        0.375      0.62711864]\n",
      " [0.36111111 0.375      0.44067797]\n",
      " [0.66666667 0.45833333 0.57627119]\n",
      " [0.36111111 0.41666667 0.59322034]\n",
      " [0.41666667 0.29166667 0.52542373]\n",
      " [0.52777778 0.08333333 0.59322034]\n",
      " [0.36111111 0.20833333 0.49152542]\n",
      " [0.44444444 0.5        0.6440678 ]\n",
      " [0.5        0.33333333 0.50847458]\n",
      " [0.55555556 0.20833333 0.66101695]\n",
      " [0.5        0.33333333 0.62711864]\n",
      " [0.58333333 0.375      0.55932203]\n",
      " [0.63888889 0.41666667 0.57627119]\n",
      " [0.69444444 0.33333333 0.6440678 ]\n",
      " [0.66666667 0.41666667 0.6779661 ]\n",
      " [0.47222222 0.375      0.59322034]\n",
      " [0.38888889 0.25       0.42372881]\n",
      " [0.33333333 0.16666667 0.47457627]\n",
      " [0.33333333 0.16666667 0.45762712]\n",
      " [0.41666667 0.29166667 0.49152542]\n",
      " [0.47222222 0.29166667 0.69491525]\n",
      " [0.30555556 0.41666667 0.59322034]\n",
      " [0.47222222 0.58333333 0.59322034]\n",
      " [0.66666667 0.45833333 0.62711864]\n",
      " [0.55555556 0.125      0.57627119]\n",
      " [0.36111111 0.41666667 0.52542373]\n",
      " [0.33333333 0.20833333 0.50847458]\n",
      " [0.33333333 0.25       0.57627119]\n",
      " [0.5        0.41666667 0.61016949]\n",
      " [0.41666667 0.25       0.50847458]\n",
      " [0.19444444 0.125      0.38983051]\n",
      " [0.36111111 0.29166667 0.54237288]\n",
      " [0.38888889 0.41666667 0.54237288]\n",
      " [0.38888889 0.375      0.54237288]\n",
      " [0.52777778 0.375      0.55932203]\n",
      " [0.22222222 0.20833333 0.33898305]\n",
      " [0.38888889 0.33333333 0.52542373]\n",
      " [0.55555556 0.54166667 0.84745763]\n",
      " [0.41666667 0.29166667 0.69491525]\n",
      " [0.77777778 0.41666667 0.83050847]\n",
      " [0.55555556 0.375      0.77966102]\n",
      " [0.61111111 0.41666667 0.81355932]\n",
      " [0.91666667 0.41666667 0.94915254]\n",
      " [0.16666667 0.20833333 0.59322034]\n",
      " [0.83333333 0.375      0.89830508]\n",
      " [0.66666667 0.20833333 0.81355932]\n",
      " [0.80555556 0.66666667 0.86440678]\n",
      " [0.61111111 0.5        0.69491525]\n",
      " [0.58333333 0.29166667 0.72881356]\n",
      " [0.69444444 0.41666667 0.76271186]\n",
      " [0.38888889 0.20833333 0.6779661 ]\n",
      " [0.41666667 0.33333333 0.69491525]\n",
      " [0.58333333 0.5        0.72881356]\n",
      " [0.61111111 0.41666667 0.76271186]\n",
      " [0.94444444 0.75       0.96610169]\n",
      " [0.94444444 0.25       1.        ]\n",
      " [0.47222222 0.08333333 0.6779661 ]\n",
      " [0.72222222 0.5        0.79661017]\n",
      " [0.36111111 0.33333333 0.66101695]\n",
      " [0.94444444 0.33333333 0.96610169]\n",
      " [0.55555556 0.29166667 0.66101695]\n",
      " [0.66666667 0.54166667 0.79661017]\n",
      " [0.80555556 0.5        0.84745763]\n",
      " [0.52777778 0.33333333 0.6440678 ]\n",
      " [0.5        0.41666667 0.66101695]\n",
      " [0.58333333 0.33333333 0.77966102]\n",
      " [0.80555556 0.41666667 0.81355932]\n",
      " [0.86111111 0.33333333 0.86440678]\n",
      " [1.         0.75       0.91525424]\n",
      " [0.58333333 0.33333333 0.77966102]\n",
      " [0.55555556 0.33333333 0.69491525]\n",
      " [0.5        0.25       0.77966102]\n",
      " [0.94444444 0.41666667 0.86440678]\n",
      " [0.55555556 0.58333333 0.77966102]\n",
      " [0.58333333 0.45833333 0.76271186]\n",
      " [0.47222222 0.41666667 0.6440678 ]\n",
      " [0.72222222 0.45833333 0.74576271]\n",
      " [0.66666667 0.45833333 0.77966102]\n",
      " [0.72222222 0.45833333 0.69491525]\n",
      " [0.41666667 0.29166667 0.69491525]\n",
      " [0.69444444 0.5        0.83050847]\n",
      " [0.66666667 0.54166667 0.79661017]\n",
      " [0.66666667 0.41666667 0.71186441]\n",
      " [0.55555556 0.20833333 0.6779661 ]\n",
      " [0.61111111 0.41666667 0.71186441]\n",
      " [0.52777778 0.58333333 0.74576271]\n",
      " [0.44444444 0.41666667 0.69491525]]\n"
     ]
    }
   ],
   "source": [
    "data_normalizada = pd.read_csv('dados/iris.csv', header=(0))\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X = np.array(data_normalizada[data_normalizada.columns[0:data.shape[1]-1]]) # Transforma√ß√£o em Array ignorando √∫ltima coluna\n",
    "for i in range(X.shape[1]):\n",
    "    print(\"MAIOR valor da coluna\", i, \"=\", max(X[:,i]))\n",
    "    print(\"MENOR Valor da coluna\", i, \"=\", min(X[:,i]))\n",
    "# prepara a fun√ß√£o para transformar os dados\n",
    "scaler = MinMaxScaler(feature_range=(0, 1)) # O m√≠nimo e o m√°ximo aqui ser√° \"0\" e \"1\"\n",
    "# Realiza a normaliza√ß√£o e coloca em um novo vetor\n",
    "X_norm = scaler.fit_transform(X) # A vari√°vel X_norm ser√° a matriz criada atrav√©s do comando .scaler\n",
    "print(X_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M√≠nimo dos atributos: [0. 0. 0.]\n",
      "M√°ximo dos atributos: [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print('M√≠nimo dos atributos:', np.amin(X_norm, axis=0))\n",
    "print('M√°ximo dos atributos:', np.amax(X_norm, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Padroniza√ß√£o <a name=\"git3.2\"></a> [ü†°](#intro)\n",
    "A **Padroniza√ß√£o** de dados possui o mesmo objetivo que a **Normaliza√ß√£o**, que √© o de transformar todos os dados para que fiquem em uma certa ordem de grandeza. A diferen√ßa √© que na Padroniza√ß√£o, **a m√©dia √© igual a 0** e **o desvio padr√£o √© igual a 1**.\n",
    "\n",
    "Vamos utilizar a biblioteca **sklearn** para padronizar nossos dados!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-9.00681170e-01  1.03205722e+00 -1.34127240e+00 -1.31297673e+00]\n",
      " [-1.14301691e+00 -1.24957601e-01 -1.34127240e+00 -1.31297673e+00]\n",
      " [-1.38535265e+00  3.37848329e-01 -1.39813811e+00 -1.31297673e+00]\n",
      " [-1.50652052e+00  1.06445364e-01 -1.28440670e+00 -1.31297673e+00]\n",
      " [-1.02184904e+00  1.26346019e+00 -1.34127240e+00 -1.31297673e+00]\n",
      " [-5.37177559e-01  1.95766909e+00 -1.17067529e+00 -1.05003079e+00]\n",
      " [-1.50652052e+00  8.00654259e-01 -1.34127240e+00 -1.18150376e+00]\n",
      " [-1.02184904e+00  8.00654259e-01 -1.28440670e+00 -1.31297673e+00]\n",
      " [-1.74885626e+00 -3.56360566e-01 -1.34127240e+00 -1.31297673e+00]\n",
      " [-1.14301691e+00  1.06445364e-01 -1.28440670e+00 -1.44444970e+00]\n",
      " [-5.37177559e-01  1.49486315e+00 -1.28440670e+00 -1.31297673e+00]\n",
      " [-1.26418478e+00  8.00654259e-01 -1.22754100e+00 -1.31297673e+00]\n",
      " [-1.26418478e+00 -1.24957601e-01 -1.34127240e+00 -1.44444970e+00]\n",
      " [-1.87002413e+00 -1.24957601e-01 -1.51186952e+00 -1.44444970e+00]\n",
      " [-5.25060772e-02  2.18907205e+00 -1.45500381e+00 -1.31297673e+00]\n",
      " [-1.73673948e-01  3.11468391e+00 -1.28440670e+00 -1.05003079e+00]\n",
      " [-5.37177559e-01  1.95766909e+00 -1.39813811e+00 -1.05003079e+00]\n",
      " [-9.00681170e-01  1.03205722e+00 -1.34127240e+00 -1.18150376e+00]\n",
      " [-1.73673948e-01  1.72626612e+00 -1.17067529e+00 -1.18150376e+00]\n",
      " [-9.00681170e-01  1.72626612e+00 -1.28440670e+00 -1.18150376e+00]\n",
      " [-5.37177559e-01  8.00654259e-01 -1.17067529e+00 -1.31297673e+00]\n",
      " [-9.00681170e-01  1.49486315e+00 -1.28440670e+00 -1.05003079e+00]\n",
      " [-1.50652052e+00  1.26346019e+00 -1.56873522e+00 -1.31297673e+00]\n",
      " [-9.00681170e-01  5.69251294e-01 -1.17067529e+00 -9.18557817e-01]\n",
      " [-1.26418478e+00  8.00654259e-01 -1.05694388e+00 -1.31297673e+00]\n",
      " [-1.02184904e+00 -1.24957601e-01 -1.22754100e+00 -1.31297673e+00]\n",
      " [-1.02184904e+00  8.00654259e-01 -1.22754100e+00 -1.05003079e+00]\n",
      " [-7.79513300e-01  1.03205722e+00 -1.28440670e+00 -1.31297673e+00]\n",
      " [-7.79513300e-01  8.00654259e-01 -1.34127240e+00 -1.31297673e+00]\n",
      " [-1.38535265e+00  3.37848329e-01 -1.22754100e+00 -1.31297673e+00]\n",
      " [-1.26418478e+00  1.06445364e-01 -1.22754100e+00 -1.31297673e+00]\n",
      " [-5.37177559e-01  8.00654259e-01 -1.28440670e+00 -1.05003079e+00]\n",
      " [-7.79513300e-01  2.42047502e+00 -1.28440670e+00 -1.44444970e+00]\n",
      " [-4.16009689e-01  2.65187798e+00 -1.34127240e+00 -1.31297673e+00]\n",
      " [-1.14301691e+00  1.06445364e-01 -1.28440670e+00 -1.44444970e+00]\n",
      " [-1.02184904e+00  3.37848329e-01 -1.45500381e+00 -1.31297673e+00]\n",
      " [-4.16009689e-01  1.03205722e+00 -1.39813811e+00 -1.31297673e+00]\n",
      " [-1.14301691e+00  1.06445364e-01 -1.28440670e+00 -1.44444970e+00]\n",
      " [-1.74885626e+00 -1.24957601e-01 -1.39813811e+00 -1.31297673e+00]\n",
      " [-9.00681170e-01  8.00654259e-01 -1.28440670e+00 -1.31297673e+00]\n",
      " [-1.02184904e+00  1.03205722e+00 -1.39813811e+00 -1.18150376e+00]\n",
      " [-1.62768839e+00 -1.74477836e+00 -1.39813811e+00 -1.18150376e+00]\n",
      " [-1.74885626e+00  3.37848329e-01 -1.39813811e+00 -1.31297673e+00]\n",
      " [-1.02184904e+00  1.03205722e+00 -1.22754100e+00 -7.87084847e-01]\n",
      " [-9.00681170e-01  1.72626612e+00 -1.05694388e+00 -1.05003079e+00]\n",
      " [-1.26418478e+00 -1.24957601e-01 -1.34127240e+00 -1.18150376e+00]\n",
      " [-9.00681170e-01  1.72626612e+00 -1.22754100e+00 -1.31297673e+00]\n",
      " [-1.50652052e+00  3.37848329e-01 -1.34127240e+00 -1.31297673e+00]\n",
      " [-6.58345429e-01  1.49486315e+00 -1.28440670e+00 -1.31297673e+00]\n",
      " [-1.02184904e+00  5.69251294e-01 -1.34127240e+00 -1.31297673e+00]\n",
      " [ 1.40150837e+00  3.37848329e-01  5.35295827e-01  2.64698913e-01]\n",
      " [ 6.74501145e-01  3.37848329e-01  4.21564419e-01  3.96171883e-01]\n",
      " [ 1.28034050e+00  1.06445364e-01  6.49027235e-01  3.96171883e-01]\n",
      " [-4.16009689e-01 -1.74477836e+00  1.37235899e-01  1.33225943e-01]\n",
      " [ 7.95669016e-01 -5.87763531e-01  4.78430123e-01  3.96171883e-01]\n",
      " [-1.73673948e-01 -5.87763531e-01  4.21564419e-01  1.33225943e-01]\n",
      " [ 5.53333275e-01  5.69251294e-01  5.35295827e-01  5.27644853e-01]\n",
      " [-1.14301691e+00 -1.51337539e+00 -2.60824029e-01 -2.61192967e-01]\n",
      " [ 9.16836886e-01 -3.56360566e-01  4.78430123e-01  1.33225943e-01]\n",
      " [-7.79513300e-01 -8.19166497e-01  8.03701950e-02  2.64698913e-01]\n",
      " [-1.02184904e+00 -2.43898725e+00 -1.47092621e-01 -2.61192967e-01]\n",
      " [ 6.86617933e-02 -1.24957601e-01  2.50967307e-01  3.96171883e-01]\n",
      " [ 1.89829664e-01 -1.97618132e+00  1.37235899e-01 -2.61192967e-01]\n",
      " [ 3.10997534e-01 -3.56360566e-01  5.35295827e-01  2.64698913e-01]\n",
      " [-2.94841818e-01 -3.56360566e-01 -9.02269170e-02  1.33225943e-01]\n",
      " [ 1.03800476e+00  1.06445364e-01  3.64698715e-01  2.64698913e-01]\n",
      " [-2.94841818e-01 -1.24957601e-01  4.21564419e-01  3.96171883e-01]\n",
      " [-5.25060772e-02 -8.19166497e-01  1.94101603e-01 -2.61192967e-01]\n",
      " [ 4.32165405e-01 -1.97618132e+00  4.21564419e-01  3.96171883e-01]\n",
      " [-2.94841818e-01 -1.28197243e+00  8.03701950e-02 -1.29719997e-01]\n",
      " [ 6.86617933e-02  3.37848329e-01  5.92161531e-01  7.90590793e-01]\n",
      " [ 3.10997534e-01 -5.87763531e-01  1.37235899e-01  1.33225943e-01]\n",
      " [ 5.53333275e-01 -1.28197243e+00  6.49027235e-01  3.96171883e-01]\n",
      " [ 3.10997534e-01 -5.87763531e-01  5.35295827e-01  1.75297293e-03]\n",
      " [ 6.74501145e-01 -3.56360566e-01  3.07833011e-01  1.33225943e-01]\n",
      " [ 9.16836886e-01 -1.24957601e-01  3.64698715e-01  2.64698913e-01]\n",
      " [ 1.15917263e+00 -5.87763531e-01  5.92161531e-01  2.64698913e-01]\n",
      " [ 1.03800476e+00 -1.24957601e-01  7.05892939e-01  6.59117823e-01]\n",
      " [ 1.89829664e-01 -3.56360566e-01  4.21564419e-01  3.96171883e-01]\n",
      " [-1.73673948e-01 -1.05056946e+00 -1.47092621e-01 -2.61192967e-01]\n",
      " [-4.16009689e-01 -1.51337539e+00  2.35044910e-02 -1.29719997e-01]\n",
      " [-4.16009689e-01 -1.51337539e+00 -3.33612130e-02 -2.61192967e-01]\n",
      " [-5.25060772e-02 -8.19166497e-01  8.03701950e-02  1.75297293e-03]\n",
      " [ 1.89829664e-01 -8.19166497e-01  7.62758643e-01  5.27644853e-01]\n",
      " [-5.37177559e-01 -1.24957601e-01  4.21564419e-01  3.96171883e-01]\n",
      " [ 1.89829664e-01  8.00654259e-01  4.21564419e-01  5.27644853e-01]\n",
      " [ 1.03800476e+00  1.06445364e-01  5.35295827e-01  3.96171883e-01]\n",
      " [ 5.53333275e-01 -1.74477836e+00  3.64698715e-01  1.33225943e-01]\n",
      " [-2.94841818e-01 -1.24957601e-01  1.94101603e-01  1.33225943e-01]\n",
      " [-4.16009689e-01 -1.28197243e+00  1.37235899e-01  1.33225943e-01]\n",
      " [-4.16009689e-01 -1.05056946e+00  3.64698715e-01  1.75297293e-03]\n",
      " [ 3.10997534e-01 -1.24957601e-01  4.78430123e-01  2.64698913e-01]\n",
      " [-5.25060772e-02 -1.05056946e+00  1.37235899e-01  1.75297293e-03]\n",
      " [-1.02184904e+00 -1.74477836e+00 -2.60824029e-01 -2.61192967e-01]\n",
      " [-2.94841818e-01 -8.19166497e-01  2.50967307e-01  1.33225943e-01]\n",
      " [-1.73673948e-01 -1.24957601e-01  2.50967307e-01  1.75297293e-03]\n",
      " [-1.73673948e-01 -3.56360566e-01  2.50967307e-01  1.33225943e-01]\n",
      " [ 4.32165405e-01 -3.56360566e-01  3.07833011e-01  1.33225943e-01]\n",
      " [-9.00681170e-01 -1.28197243e+00 -4.31421141e-01 -1.29719997e-01]\n",
      " [-1.73673948e-01 -5.87763531e-01  1.94101603e-01  1.33225943e-01]\n",
      " [ 5.53333275e-01  5.69251294e-01  1.27454998e+00  1.71090158e+00]\n",
      " [-5.25060772e-02 -8.19166497e-01  7.62758643e-01  9.22063763e-01]\n",
      " [ 1.52267624e+00 -1.24957601e-01  1.21768427e+00  1.18500970e+00]\n",
      " [ 5.53333275e-01 -3.56360566e-01  1.04708716e+00  7.90590793e-01]\n",
      " [ 7.95669016e-01 -1.24957601e-01  1.16081857e+00  1.31648267e+00]\n",
      " [ 2.12851559e+00 -1.24957601e-01  1.61574420e+00  1.18500970e+00]\n",
      " [-1.14301691e+00 -1.28197243e+00  4.21564419e-01  6.59117823e-01]\n",
      " [ 1.76501198e+00 -3.56360566e-01  1.44514709e+00  7.90590793e-01]\n",
      " [ 1.03800476e+00 -1.28197243e+00  1.16081857e+00  7.90590793e-01]\n",
      " [ 1.64384411e+00  1.26346019e+00  1.33141568e+00  1.71090158e+00]\n",
      " [ 7.95669016e-01  3.37848329e-01  7.62758643e-01  1.05353673e+00]\n",
      " [ 6.74501145e-01 -8.19166497e-01  8.76490051e-01  9.22063763e-01]\n",
      " [ 1.15917263e+00 -1.24957601e-01  9.90221459e-01  1.18500970e+00]\n",
      " [-1.73673948e-01 -1.28197243e+00  7.05892939e-01  1.05353673e+00]\n",
      " [-5.25060772e-02 -5.87763531e-01  7.62758643e-01  1.57942861e+00]\n",
      " [ 6.74501145e-01  3.37848329e-01  8.76490051e-01  1.44795564e+00]\n",
      " [ 7.95669016e-01 -1.24957601e-01  9.90221459e-01  7.90590793e-01]\n",
      " [ 2.24968346e+00  1.72626612e+00  1.67260991e+00  1.31648267e+00]\n",
      " [ 2.24968346e+00 -1.05056946e+00  1.78634131e+00  1.44795564e+00]\n",
      " [ 1.89829664e-01 -1.97618132e+00  7.05892939e-01  3.96171883e-01]\n",
      " [ 1.28034050e+00  3.37848329e-01  1.10395287e+00  1.44795564e+00]\n",
      " [-2.94841818e-01 -5.87763531e-01  6.49027235e-01  1.05353673e+00]\n",
      " [ 2.24968346e+00 -5.87763531e-01  1.67260991e+00  1.05353673e+00]\n",
      " [ 5.53333275e-01 -8.19166497e-01  6.49027235e-01  7.90590793e-01]\n",
      " [ 1.03800476e+00  5.69251294e-01  1.10395287e+00  1.18500970e+00]\n",
      " [ 1.64384411e+00  3.37848329e-01  1.27454998e+00  7.90590793e-01]\n",
      " [ 4.32165405e-01 -5.87763531e-01  5.92161531e-01  7.90590793e-01]\n",
      " [ 3.10997534e-01 -1.24957601e-01  6.49027235e-01  7.90590793e-01]\n",
      " [ 6.74501145e-01 -5.87763531e-01  1.04708716e+00  1.18500970e+00]\n",
      " [ 1.64384411e+00 -1.24957601e-01  1.16081857e+00  5.27644853e-01]\n",
      " [ 1.88617985e+00 -5.87763531e-01  1.33141568e+00  9.22063763e-01]\n",
      " [ 2.49201920e+00  1.72626612e+00  1.50201279e+00  1.05353673e+00]\n",
      " [ 6.74501145e-01 -5.87763531e-01  1.04708716e+00  1.31648267e+00]\n",
      " [ 5.53333275e-01 -5.87763531e-01  7.62758643e-01  3.96171883e-01]\n",
      " [ 3.10997534e-01 -1.05056946e+00  1.04708716e+00  2.64698913e-01]\n",
      " [ 2.24968346e+00 -1.24957601e-01  1.33141568e+00  1.44795564e+00]\n",
      " [ 5.53333275e-01  8.00654259e-01  1.04708716e+00  1.57942861e+00]\n",
      " [ 6.74501145e-01  1.06445364e-01  9.90221459e-01  7.90590793e-01]\n",
      " [ 1.89829664e-01 -1.24957601e-01  5.92161531e-01  7.90590793e-01]\n",
      " [ 1.28034050e+00  1.06445364e-01  9.33355755e-01  1.18500970e+00]\n",
      " [ 1.03800476e+00  1.06445364e-01  1.04708716e+00  1.57942861e+00]\n",
      " [ 1.28034050e+00  1.06445364e-01  7.62758643e-01  1.44795564e+00]\n",
      " [-5.25060772e-02 -8.19166497e-01  7.62758643e-01  9.22063763e-01]\n",
      " [ 1.15917263e+00  3.37848329e-01  1.21768427e+00  1.44795564e+00]\n",
      " [ 1.03800476e+00  5.69251294e-01  1.10395287e+00  1.71090158e+00]\n",
      " [ 1.03800476e+00 -1.24957601e-01  8.19624347e-01  1.44795564e+00]\n",
      " [ 5.53333275e-01 -1.28197243e+00  7.05892939e-01  9.22063763e-01]\n",
      " [ 7.95669016e-01 -1.24957601e-01  8.19624347e-01  1.05353673e+00]\n",
      " [ 4.32165405e-01  8.00654259e-01  9.33355755e-01  1.44795564e+00]\n",
      " [ 6.86617933e-02 -1.24957601e-01  7.62758643e-01  7.90590793e-01]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = pd.read_csv('dados/iris.csv', header=(0))\n",
    "data_matriz = np.array(data[data.columns[0:data.shape[1]-1]]) # arquivo CSV transformado em matriz (array)\n",
    "padronizador = StandardScaler().fit(data_matriz) # m√©dia = 0, desvio padr√£o = 1\n",
    "matriz_padronizada = padronizador.transform(data_matriz)\n",
    "\n",
    "print(matriz_padronizada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√â interessante notar que agora possu√≠mos valores **negativos** em nossa matriz padronizada. Isso acontece pois **a m√©dia √© igual a zero**, al√©m do desvio padr√£o igual a **um**.\n",
    "\n",
    "Vamos calcular a m√©dia de cada coluna da nossa matriz padronizada!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A M√©dia da coluna 0 √©: -4.736951571734001e-16\n",
      "O desvio padr√£o da coluna 0 √©: 1.0 \n",
      "\n",
      "A M√©dia da coluna 1 √©: -6.631732200427602e-16\n",
      "O desvio padr√£o da coluna 1 √©: 0.9999999999999999 \n",
      "\n",
      "A M√©dia da coluna 2 √©: 3.315866100213801e-16\n",
      "O desvio padr√£o da coluna 2 √©: 0.9999999999999998 \n",
      "\n",
      "A M√©dia da coluna 3 √©: -2.842170943040401e-16\n",
      "O desvio padr√£o da coluna 3 √©: 1.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0,matriz_padronizada.shape[1]):\n",
    "    print('A M√©dia da coluna', i, '√©:', np.mean(matriz_padronizada[:,i]))\n",
    "    print('O desvio padr√£o da coluna', i, '√©:', np.std(matriz_padronizada[:,i]), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos interpretar **e-16** como sendo **muito pr√≥ximo de zero**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Binariza√ß√£o dos dados <a name=\"git4\"></a> [ü†°](#intro)\n",
    "Utilizamos dados bin√°rios para casos em que certo valor = 0 e um outro valor = 1, normalmente indicando \"n√£o\" e \"sim\", ou \"desligado\" e \"ligado\".\n",
    "\n",
    "Ao receber dados de exame de sangue de diversas pessoas, n√≥s gostar√≠amos de saber se essa pessoa est√° **deficiente de ferro**. Para isso, diremos que:\n",
    "1. Deficiente de ferro se a ferritina est√° **abaixo** de 30 microgramas\\L;\n",
    "2. N√£o deficiente se a ferritina est√° **acima** de 30 microgramas\\L.\n",
    "\n",
    "Atente para o fato de que **n√£o estar deficiente** de ferro N√ÉO significa que ela est√° normalizada, pois uma grande quantidade de ferro pode representar outro tipo de doen√ßa.\n",
    "\n",
    "Sendo assim, os valores ser√£o **binarizados**:\n",
    "1. Deficiente de ferro ser√° **0**;\n",
    "2. N√£o deficiente de ferro ser√° **1**.\n",
    "\n",
    "Vamos **criar uma tabela fict√≠cia** utilizando a biblioteca nativa **csv**. \n",
    "\n",
    "Depois vamos transformar os dados utilizando a biblioteca **sklearn** e suas etiquetas **Binarizer** e **MinMaxScaler**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limiar: 30\n",
      "-------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_padronizado' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-179-4c2305f0135e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mX_binarizado\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbinarizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#(X_padronizado)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_padronizado\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Antes:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Depois:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_binarizado\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_padronizado' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import csv\n",
    "\n",
    "#Criando uma tabela com dados fict√≠cios\n",
    "with open('dados/dados_ferritina_sangue.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    writer.writerow([\"C√≥digo\", \"Ferritina em microgramas\\L\"])\n",
    "    writer.writerow([32.8, \"PACIENTE A\"])       \n",
    "    writer.writerow([30.1, \"PACIENTE B\"])\n",
    "    writer.writerow([29.9, \"PACIENTE C\"])\n",
    "    writer.writerow([27.6, \"PACIENTE D\"])\n",
    "    writer.writerow([64.3, \"PACIENTE E\"])\n",
    "    writer.writerow([45.1, \"PACIENTE F\"])\n",
    "\n",
    "    \n",
    "data_ferritina = pd.read_csv('dados/dados_ferritina_sangue.csv', header=(0), encoding = \"ISO-8859-1\")\n",
    "\n",
    "# Transformando a tabela em matriz (array) e considerando apenas os atributos da coluna 1.\n",
    "X = np.array(data_ferritina[data_ferritina.columns[0:1]])\n",
    "\n",
    "T = 30 # valor do Limiar / Treshold\n",
    "print('Limiar:', T)\n",
    "print(\"-------------------\")\n",
    "\n",
    "# Binariza√ß√£o dos dados considerando o limiar T (threshhold)\n",
    "binarizer = Binarizer(threshold=T).fit(X) #.fit(X_padronizado)\n",
    "X_binarizado = binarizer.transform(X) #(X_padronizado)\n",
    "\n",
    "for i in np.arange(0, X_padronizado.shape[0]):\n",
    "    print(\"Antes:\", X[i,])\n",
    "    print(\"Depois:\", X_binarizado[i, ])\n",
    "    print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Transformando vari√°veis nominais em n√∫meros inteiros <a name=\"git5\"></a> [ü†°](#intro)\n",
    "Esse √© mais simples. Caso queira transformar algum tipo de vari√°vel nominal em n√∫meros inteiros, basta indicar **o termo a ser substitu√≠do** e **em que ele se transformar√°**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dados/iris.csv', header=(0))\n",
    "\n",
    "classes = np.unique(data[data.columns[-1]])\n",
    "number = 0 # valor que a classe ser√° transformada\n",
    "\n",
    "for i in classes:\n",
    "    data = data.replace(i, number) # cada classe corresponder√° a um valor, respectivamente\n",
    "    number = number + 1 # esperamos que seja setosa = 0, versicolor = 1 e virginica = 2\n",
    "\n",
    "classes_novas = np.unique(data[data.columns[-1]])\n",
    "\n",
    "print(\"Dados antigos:\", classes)\n",
    "print(\"Novos dados:\", classes_novas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tamb√©m √© poss√≠vel fazer o processo contr√°rio! Vamos pegar os dados de ferritina no sangue e, se o n√∫mero for menor do que 30, ele ser√° transformado em **DEFICIENTE EM FERRITINA**. Se for maior ou igual a 30, **N√ÉO DEFICIENTE EM FERRITINA**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ferritina = pd.read_csv('dados/dados_ferritina_sangue.csv', header=(0), encoding = \"ISO-8859-1\")\n",
    "classes_ferritina = np.unique(data_ferritina[data_ferritina.columns[0]])\n",
    "\n",
    "deficiente = \"DEFICIENTE EM FERRITINA\" # valor STRING em que a classe ser√° transformada\n",
    "nao_deficiente = \"N√ÉO DEFICIENTE EM FERRITINA\" # valor STRING em que a classe ser√° transformada\n",
    "number = 30.0\n",
    "\n",
    "print(data_ferritina)\n",
    "\n",
    "for i in classes_ferritina:\n",
    "    if i < 30:\n",
    "        data_ferritina = data_ferritina.replace(i, deficiente)\n",
    "    else:\n",
    "        data_ferritina = data_ferritina.replace(i, nao_deficiente)\n",
    "\n",
    "\n",
    "\n",
    "classes_ferritina_novas = np.unique(data_ferritina[data_ferritina.columns[0]])\n",
    "\n",
    "#print(\"\\nDados antigos:\", classes_ferritina,)\n",
    "#print(\"Novos dados:\", classes_ferritina_novas)\n",
    "\n",
    "print(\"\\nAgora a tabela ficou assim:\\n\")\n",
    "print(data_ferritina)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. One-hot encoding: transformando valores em c√≥digos bin√°rios <a name=\"git6\"></a> [ü†°](#intro)\n",
    "O **one-hot encoding** √© uma outra forma de trabalhar com bin√°rios. Pode ser feito de maneira autom√°tica com poucas linhas de c√≥digo. Basicamente, contar√° o n√∫mero de vari√°veis diferentes, atribuindo valor bin√°rio com mais de uma coluna.\n",
    "\n",
    "Com o exemplo, ficar√° muito mais compreens√≠vel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Vamos criar um DataFrame com o pandas\n",
    "df = pd.DataFrame ({'A':['a', 'b', 'c', 'd'],}) # Podemos contar QUATRO vari√°veis diferentes aqui: a, b, c, d\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df) # Vamos usar o one-hot encoding\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viu como transformamos os diferentes atributos em **c√≥digos bin√°rios**?\n",
    "- O **a** agora √© 1 0 0 0\n",
    "- O **d** agora √© 0 0 0 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Correlacionando dados <a name=\"git7\"></a> [ü†°](#intro)\n",
    "**Correlacionar dados** significa identificar, dentre variantes, colunas ou qualquer outro tipo de atributo, **quais os atributos que possuem maior ou menor correla√ß√£o**, e medi-la.\n",
    "\n",
    "Para exemplificar, vamos correlacionas os dados da base de dados **BostonHousing**, que √© bem conhecida e que relaciona Casas com Pre√ßos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_housing = pd.read_csv('dados/BostonHousing.csv', header=(0))\n",
    "data_housing.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data_housing.corr()  # corr √© o m√©todo de correla√ß√£o do Pandas. Acabamos de correlacionar os dados!\n",
    "\n",
    "# Daqui para baixo, estaremos gerando o gr√°fico de correla√ß√£o\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(corr, cmap='Blues', interpolation='none', aspect='auto') # imshow exibe data como uma imagem\n",
    "plt.colorbar() # gera a barra do lado direito\n",
    "\n",
    "# Vamos incluir o nome de todas as vari√°veis\n",
    "plt.xticks(range(len(corr)), corr.columns, rotation='vertical') # adiciona as vari√°veis na linha X\n",
    "plt.yticks(range(len(corr)), corr.columns); # adiciona as vari√°veis na linha Y\n",
    "plt.suptitle('Correlation between variables', fontsize=15, fontweight='bold') # adiciona um t√≠tulo\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisar o gr√°fico pode n√£o ser t√£o intuitivo assim. Se voc√™ ainda n√£o sabe como fazer, √© bem simples! A correla√ß√£o est√° sendo contada de **0** a **1**, como mostra a barra lateral direita.\n",
    "\n",
    "Nessa mesma barra lateral, podemos ver que:\n",
    "- Quanto **mais clara** a cor, **menos correla√ß√£o** entre vari√°veis x e y temos, ou seja, correla√ß√£o se aproxima de **0**;\n",
    "- Quanto **mais escura** a cor, **mais correla√ß√£o** entre vari√°veis x e y temos, ou seja, correla√ß√£o se aproxima de **1**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N√≥s geramos um gr√°fico para que seja melhor de entender o que est√° ocorrendo nesse _dataset_, por√©m saiba que os dados est√£o armazenados em uma matriz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percebeu que o **n√∫mero m√°ximo** √© **1**? Isso est√° ocorrendo por conta do m√©todo utilizar a **Correla√ß√£o de Pearson**. Aqui est√° a descri√ß√£o do Wikipedia:\n",
    "\n",
    "Em estat√≠stica descritiva, o coeficiente de correla√ß√£o de Pearson, tamb√©m chamado de \"coeficiente de correla√ß√£o produto-momento\" ou simplesmente de \"œÅ de Pearson\" mede o grau da correla√ß√£o (e a direc√ß√£o dessa correla√ß√£o - se positiva ou negativa) entre duas vari√°veis de escala m√©trica (intervalar ou de r√°cio/raz√£o).\n",
    "\n",
    "Este coeficiente, normalmente representado por œÅ assume apenas valores entre -1 e 1:\n",
    "- **œÅ = 1** significa uma **correla√ß√£o positiva perfeita** entre as duas vari√°veis;\n",
    "- **œÅ = -1** significa uma **correla√ß√£o negativa perfeita** entre as duas vari√°veis. **Se uma aumenta, a outra sempre diminui**;\n",
    "- **œÅ = 0** significa que as duas vari√°veis **n√£o dependem linearmente uma da outra**. No entanto, pode existir uma depend√™ncia n√£o linear. Assim, o resultado **œÅ = 0** deve ser investigado por outros meios.\"\n",
    "\n",
    "\n",
    "Vamos agora identificar quais as vari√°veis que possuem **maior correla√ß√£o**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.75 # Essa √© a correla√ß√£o m√≠nima que estamos considerando\n",
    "var = []\n",
    "for i in corr.columns: # percorre toda a tabela para cara elemento \"i\"\n",
    "    for j in corr.columns: # percorre novamente toda a tabela para cada elemento \"j\"\n",
    "        if(i != j):\n",
    "            if np.abs(corr[i][j]) > p: # Se a correla√ß√£o for maior que \"p\"\n",
    "                var.append([i,j]) # Coloca na lista \"var\"\n",
    "                \n",
    "print('As vari√°veis com maior correla√ß√£o:\\n', var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse tipo de m√©todo √© muito importante pois tamb√©m nos ajuda a filtrar melhor o _dataset_. Se dois dados s√£o muito correlacionados, um deles pode ser removido, pois podem ter um significado muito pr√≥ximo e interferir em outros dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Dados desbalanceados: como detectar, analisar e balancear <a name=\"git8\"></a> [ü†°](#intro)\n",
    "Em uma amostragem de dados, possivelmente alguns deles podem estar **desbalanceados**. Isso ocorre quando o _dataset_ possui quantidades diferentes de elementos por classe. Quanto **maior a dist√¢ncia** entre a quantidade de elementos entre classes, **maior o desbalanceamento**. Vamos entender melhor com o pr√≥ximo exemplo.\n",
    "\n",
    "Para calcularmos quantas classes possui um _dataset_, basta contarmos atrav√©s da coluna de classes. No _dataset_ abaixo, a coluna de classes √© a √∫ltima, que indica qual o tipo de ve√≠culo da linha correspondente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_veiculo = pd.read_csv('dados/Vehicle.csv', header=(0))\n",
    "data_veiculo.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coluna_class = data_veiculo[data_veiculo.columns[-1]] # Vamos colocar a coluna \"class\" em uma vari√°vel\n",
    "print(coluna_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos separar a coluna class por elementos e contar a ocorr√™ncia de cada um deles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipos_de_classe = np.unique(coluna_class) # Vamos pegar o nome dos diferentes elementos da coluna \"class\"\n",
    "print(tipos_de_classe)\n",
    "print(tipos_de_classe[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos pegar o n√∫mero de ocorr√™ncia de cada uma das quatro diferentes classes guardadas na vari√°vel acima\n",
    "numero_de_classes = np.zeros(len(tipos_de_classe)) # pega qual a quantidade de classes diferentes, que √© quatro\n",
    "\n",
    "\n",
    "for i in np.arange(0, len(tipos_de_classe)): # para os elementos \"i\" de \"0\" at√© \"quantidade de classes diferentes\"\n",
    "    a = coluna_class == tipos_de_classe[i] # \"a\" √© vari√°vel da coluna_class, que √© equivalente ao tipo de classe \"i\"\n",
    "    numero_de_classes[i] = len(coluna_class[a]) # quantidade de apari√ß√£o do elemento \"i\"\n",
    "    \n",
    "print(numero_de_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma boa forma de analisar visualmente √© utilizando o gr√°fico do tipo **Histograma**, que exibir√° a quantidade de ocorr√™ncia por elemento (por tipo de ve√≠culo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "numbers = np.arange(0, len(tipos_de_classe))\n",
    "plt.bar(numbers, numero_de_classes, alpha=.75)\n",
    "\n",
    "# Agora vamos exibir o nome das classes ao inv√©s de exibir n√∫meros\n",
    "plt.xticks(numbers, tipos_de_classe)\n",
    "plt.title('N√∫mero de elementos por classe')\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao obter a quantidade de elementos por classe, e ao analisar o Histograma acima, √© poss√≠vel concluir que **as classes est√£o bem distribu√≠das**, possuindo pouca dist√¢ncia entre quantidades. \n",
    "\n",
    "Por√©m, ainda assim podemos realizar uma redistribui√ß√£o de dados para que tenhamos um **balanceamento perfeito**. O resultado ser√° cada classe com o mesmo n√∫mero de elementos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3 # Vamos selecionar apenas tr√™s ocorr√™ncias de cada classe e seus respectivos atributos.\n",
    "\n",
    "# classes\n",
    "cl = np.unique(coluna_class) #pega o n√∫mero de diferentes classes\n",
    "X = np.array(data_veiculo) #transforma o dataset em uma matriz/array\n",
    "Xnew = [] # este ser√° o array que receber√° appends, por enquanto est√° vazio\n",
    "cls = np.array(data_veiculo[data_veiculo.columns[-1]])\n",
    "\n",
    "for i in np.arange(0, len(cl)): # de 0 at√© o tamanho(n√∫mero de diferentes classes)\n",
    "    a = np.argwhere(cls == cl[i])\n",
    "    inds = np.random.choice(a[:,0], N, replace=False) # Aleatoriamente, seleciona um elemento \"a\" qualquer \"N\" vezes\n",
    "    Xnew.append(X[inds,:]) # append do valor armazenado na vari√°vel inds\n",
    "    \n",
    "Xnew = np.array(Xnew) # transforma Xnew em array estruturado\n",
    "\n",
    "print('Dados obtidos a partir da amostragem')\n",
    "print(Xnew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. An√°lise de Componentes Principais (PCA) <a name=\"git9\"></a> [ü†°](#intro)\n",
    "A **An√°lise de Componentes Principais** ou **Principal Components Analisis (PCA)** envolve teoria de **espectro de matrizes**, o que foge da √°lgebra linear. Por fugir muito das an√°lises vistas aqui nesse guia, a teoria n√£o ser√° passada POR ENQUANTO.\n",
    "\n",
    "Ele √© utilizado com a finalidade de analisar dados eliminando sobreposi√ß√µes e utilizando as formas mais representativas dos dados.\n",
    "\n",
    "Vamos realizar essa an√°lise atrav√©s de poucas linhas de c√≥digo! O mais interessante √© o resultado gr√°fico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('dados/Iris.csv', header=(0))\n",
    "coluna_class = np.unique(data[data.columns[-1]]) # Vamos guardar a √∫ltima coluna, 'Class'\n",
    "print(data.shape) # Atrav√©s desse print, vemos que possui 150 linhas e 5 colunas\n",
    "list_labels = list(data.columns)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to_numpy() # Transformando o dataset em formato NumPy\n",
    "nrow,ncol = data.shape\n",
    "y = data[:,-1] \n",
    "X = data[:,0:ncol-1] # '-1' para ignorar a √∫ltima coluna, que √© a de Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos **padronizar** os dados utilizando o **sklearn**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos finalmente realizar a **PCA**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2) # N√∫mero de componentes\n",
    "pca_resultado = pca.fit_transform(X)\n",
    "\n",
    "# Vamos alterar os atributos do gr√°fico e exibi-lo utilizando o matplotlib\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(pca_resultado[:,0], pca_resultado[:,1], s=50, color = 'blue') # primeiro '0' e segundo eixo '1'\n",
    "plt.xlabel(\"Primeiro componente\", fontsize=20)\n",
    "plt.ylabel(\"Segundo componente\", fontsize=20)\n",
    "plt.xticks(color='k', size=20)\n",
    "plt.yticks(color='k', size=20)\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora vamos colorir de acordo com a classe dos dados, o que facilita muito na hora de analisar!\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'w']\n",
    "aux = 0\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "for c in coluna_class:\n",
    "    nodes = np.where(y == c)\n",
    "    plt.scatter(pca_resultado[nodes,0], pca_resultado[nodes,1], s=50, color = colors[aux], label = c)\n",
    "    aux = aux + 1\n",
    "    \n",
    "plt.legend()   \n",
    "plt.xlabel(\"Primeiro componente\", fontsize=20)\n",
    "plt.ylabel(\"Segundo componente\", fontsize=20)\n",
    "plt.xticks(color='k', size=20)\n",
    "plt.yticks(color='k', size=20)\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√â poss√≠vel perceber como fica f√°cil, atrav√©s da an√°lise **PCA**, o qu√£o pr√≥ximas ou distantes est√£o as classes:\n",
    "1. A setosa √© muito diferente da versicolor e da virginica;\n",
    "2. A versicolor e virginica s√£o diferentes;\n",
    "3. Entre a versicolor e a virginica, alguns valores se confundem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Boxplot: detectando, exibindo e descartando _outliers_ <a name=\"git10\"></a> [ü†°](#intro)\n",
    "Vamos verificar se h√° a presen√ßa de **outliers** em nossos _datasets_! Para isso, utilizaremos o gr√°fico do tipo **Boxplot**. \n",
    "\n",
    "Os **outliers** s√£o dados que possuem diferen√ßas significativas em rela√ß√£o √† maioria. Eles podem prejudicar muito o c√°lculo da **M√©dia** de um conjunto de dados.\n",
    "\n",
    "Para gerar o tal gr√°fico **Boxplot**, s√£o necess√°rios alguns elementos, que ser√£o calculados apenas na pr√≥xima aula!\n",
    "1. A **Mediana** de um conjunto de dados;\n",
    "1. **1¬∫ e 3¬∫ Quartil** de um conjunto de dados;\n",
    "2. Um valor arbitr√°rio de M√≠nimo e M√°ximo. Quem estiver fora dessa defini√ß√£o √© considerado um **outlier**.\n",
    "\n",
    "Vamos importar o _dataset_ \"iris.csv\" e exibir o Boxplot dele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns # √â uma biblioteca de exibi√ß√£o gr√°fica\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_iris = pd.read_csv('dados/iris.csv', header=(0))\n",
    "print(data_iris) # Vamos exibir o print para compararmos com o gr√°fico\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Vamos alterar a exibi√ß√£o dos elementos do Boxplot e exibi-lo\n",
    "sns.boxplot(x=\"species\", y=\"petal_length\", data=data_iris) # √â aqui que definimos o que ser√° o atributo \"x\" e o \"y\"\n",
    "plt.xlabel('Esp√©cie', fontsize=18)\n",
    "plt.ylabel('Comprimento da p√©tala', fontsize=16)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceba como conseguimos gerar o Boxplot da variante **petal_length** de cada uma das classes existentes em **species**. A linha do c√≥digo que realizou essa defini√ß√£o foi essa:\n",
    "\n",
    "``sns.boxplot(x=\"species\", y=\"petal_length\", data=data_iris) # √â aqui que definimos o que ser√° o atributo \"x\" e o \"y\"``\n",
    "\n",
    "Na pr√≥xima aula, aprenderemos muito mais sobre como funcionam os c√°lculos. Aqui estamos apenas indicando uma forma f√°cil de encontrar esses dados e exibi-los graficamente.\n",
    "\n",
    "Vamos agora detectar a dist√¢ncia interquantil (Q3 - Q1) para encontrar os **outliers** e exibilos graficamente!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Vamos gerar dados de forma rand√¥mica valores de '1' a '200' para as vari√°veis 'a', 'b' e 'c'\n",
    "data = pd.DataFrame({'a': np.random.randint(1, 200, 20),\n",
    "                    'b': np.random.randint(1, 200, 20),\n",
    "                    'c': np.random.randint(1, 200, 20)})\n",
    "\n",
    "# Vamos agora gerar alguns outliers. Os valores acima de 150 ser√£o multiplicados em 10.\n",
    "data[data > 150] = data[data > 150]*10\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos exibir um gr√°fico do _dataset_ criado utilizando a biblioteca **seaborn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn\n",
    "seaborn.pairplot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos detectar os outliers utilizando a **dist√¢ncia interquartil** (**IQR**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = data.quantile(0.25) #primeiro quartil, ou seja 25% do dataset\n",
    "Q3 = data.quantile(0.75) #terceiro quartil, ou seja, 75% do dataset\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "print(((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True s√£o os valores **menores que (Q1 - 1.5 * IQR) e maiores que (Q3 + 1.5 * IQR)**, ou seja, s√£o os os elementos **outliers**, que ultrapassam os limites do gr√°fico **Boxplot**, visto anteriormente. O Boxplot **exclui** os dados outliers da an√°lise, para n√£o interferir na exibi√ß√£o e leitura gr√°fica.\n",
    "\n",
    "Novamente, se restaram d√∫vidas, n√£o se preocupe pois trataremos desse dados **outliers** na pr√≥xima aula.\n",
    "\n",
    "Por fim, **vamos deletar** as linhas que contenham algum dado outlier, para que ele n√£o interfira em outros tipos de an√°lise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = ((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))).any(axis=1) # axis=1 significa linha, axis=0 significa coluna\n",
    "data = data.drop(data.index[list(v)], axis=0) # Vamos deletar os valores 'v' utilizando data.drop\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceba como agora s√≥ ficaram as linhas em que todos os atributos tinham classifica√ß√£o **False** para outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basicamente, essas s√£o as formas mais utilizadas de exibi√ß√£o e tratamento de dados na Ci√™ncia de Dados.** At√© o pr√≥ximo guia!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
