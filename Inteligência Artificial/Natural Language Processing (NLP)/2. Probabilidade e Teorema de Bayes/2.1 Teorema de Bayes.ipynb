{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Teorema de Bayes\n",
    "O **Teorema de Bayes**, criado por um pastor e matemático inglês chamado Thomas Bayes no século XVIII, é uma fórmula matemática utilizada para calcular a **probabilidade estatística**. Antes de conhecermos o teorema, precisamos compreender o que é a **probabilidade condicional** (ou probabilidade condicionada), que é utilizada no teorema.\n",
    "\n",
    "### 2.1.1 Probabilidade Condicional\n",
    "#### Primeiro caso\n",
    "Se, ao invés de considerarmos um corpus inteiro de tweets, o que acontece se considerarmos apenas a parte que possui os tweets contendo a palavra \"happy\"? Existe uma parte com a classificação \"Positive\" (**área vermelha**) e uma parte sem essa classificação (**área azul**).\n",
    "\n",
    "<img src=\"images/probabilidade condicional.png\" width=60%>\n",
    "\n",
    "Em outras palavras, dentro do círculo azul, sabemos que 100% dos tweets possuem a palavra \"happy\", porém existe uma parte (25%) que ainda não foi classificada. Podemos calcular e chegar a uma probabilidade de 75% para que um tweet satisfaça as duas **condições** ('Positivo' + 'happy') fazendo o seguinte cálculo: \n",
    "* **O número de tweets contendo (happy + 'Positive') dividido pelo número de tweets contendo apenas \"happy\".** Ou seja, 3/4 = **0.75**.\n",
    "* P(A|B) = P(Positive|\"happy\")\n",
    "* P(A|B) = 3/4 = **0.75**\n",
    "\n",
    "O **P(B|A)** significa: probabilidade de \"A\" acontecer dado que \"B\" já aconteceu. Em outras palavras, **probabilidade de um tweet ser classificado como 'Positive', sabendo que o mesmo contém a palavra 'happy'**.\n",
    "\n",
    "#### Segundo caso\n",
    "<img src=\"images/probabilidade condicional2.png\" width=60%>\n",
    "\n",
    "Vamos fazer o mesmo agora para os casos 'Positivos', onde a área em **roxo** são os tweets que possuem duas condições (a palavra \"**happy**\" e classificados como '**Positive**'). Já a área verde são os tweets 'Positives' que não possuem a palavra '**happy**'. Para calcular a probabilidade de uma palavra satisfazer **as duas condições** (ser 'happy' + 'Positive') dentro dessa área do Corpus, precisamos realizar o mesmo tipo de cálculo:\n",
    "* O número de tweets ('happy' + 'Positive') dividido pelo número de tweets 'Positives'. Ou seja, 3/13 = **0.231**.\n",
    "* P(B|A) = P(\"happy\"|Positive)\n",
    "* P(B|A) = 3/13 = 0.231\n",
    "\n",
    "O **P(B|A)** significa: probabilidade de \"B\" acontecer dado que \"A\" já aconteceu. Em outras palavras, **probabilidade de um tweet conter 'happy', sabendo que este já é categorizado como 'Positive'**.\n",
    "\n",
    "#### Terceiro caso\n",
    "Vamos calcular, utilizando o mesmo conjunto acima, a probabilidade do **inverso** acontecer. Ou seja, P(A|B):\n",
    "* P(A|B) = P(Positive|\"happy\")\n",
    "* P(A|B) = 13/3 $\\approx$ 4,33\n",
    "\n",
    "Algo estranho aconteceu, certo? Você consegue adivinhar por que não deu para realizar o cálculo acima? Por qual motivo ele \"quebrou\"? Não veja a resposta ainda!\n",
    "\n",
    "<details>\n",
    "<summary>Resposta</summary>\n",
    "Quando tentamos calcular a probabilidade de um tweet ser \"Positive\" (13) sabendo que ele já satisfaz a condição de conter a palavra \"happy\" (3), estamos levando em conta:\n",
    "\n",
    "    * Uma região em que TODOS OS TWEETS JÁ SATISFAZEM a condição de serem \"Positive\";\n",
    "    \n",
    "Ou seja, o que a gente tentou calcular é a probabilidade de um evento ocorrer (happy + Positive), sendo que ele já estava ocorrendo dentro de seu contexto (Positive). Os elementos (happy + Positive) são uma sub-categoria de \"Positive\".\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Mas o que posso tirar desses exemplos?\n",
    "Você deve ter reparado que estamos lidando com exemplos em que calculamos a **probabilidade de um evento ocorrer**, e ele precisa necessariamente de uma **condição em falta**:\n",
    "1. No primeiro caso, encontramos a probabilidade de um tweet ser 'Positivo', sabendo que ele satisfaz a condição de conter 'happy';\n",
    "2. No segundo caso, encontramos a probabilidade de um tweet contér a palavra 'happy', sabendo que ele satisfaz a condição de ser 'Positivo'.\n",
    "\n",
    "Nos dois casos apresentados, **faltava uma condição a ser preenchida**. Já no terceiro, **a condição já estava preenchida**, portanto o cálculo não pôde ser realizado.\n",
    "\n",
    "Quando estamos lidando com casos em que uma certa **condição** está faltando, como nos casos acima em que \"faltava\" classificar um certo número de tweets, estamos no terreno da **probabilidade condicionada**. Ou seja:\n",
    "1. A probabilidade de **B** ocorrer, levando em conta que **A** aconteceu; ou\n",
    "2. Conhecendo todos os elementos do conjunto **A**, a probabilidade do mesmo elemento também pertencer ao conjunto **B**.\n",
    "\n",
    "<img src=\"images/probabilidade condicional3.png\" width=40%>\n",
    "\n",
    "Lembra da imagem acima, que conhecemos no guia anterior? **Esse diagrama contém os dois casos apresentados nesse guia**, onde temos um conjunto de tweets \"**Positivos**\" (círculo verde) e um conjunto de tweets contendo \"**happy**\" (círculo azul):\n",
    "1. Na **área azul** os elementos satisfazem apenas uma condição: possuir a palavra \"**happy**\";\n",
    "3. Na **área verde** os elementos satisfazem apenas uma condição: possuir a categoria \"**Positive**\";\n",
    "2. Na **área vermelha**, existe a intersecção entre as duas condições, ou seja, **representa um conjunto que satisfaz as duas condições**. \n",
    "\n",
    "\n",
    "Podemos realizar **um novo tipo de cálculo**, agora olhando para esse diagrama e levando em conta suas intersecções, por exemplo:\n",
    "#### Qual a chance do tweet que só possui a condição \"happy\" (**área azul**), ser classificado como \"Positive\" (**círculo verde**)?\n",
    "Para isso, utilizamos a equação abaixo:\n",
    "1. P(Positive|\"happy\") = $ \\dfrac{P(\\text{Positive } \\cap \\text{\"happy\"})}{P(\\text{\"happy\"})}$\n",
    "\n",
    "Essa mesma equação pode ser reescrita, apenas trocando a posição das duas condições:\n",
    "\n",
    "2. P(\"happy\"|\"Positive\") = $ \\dfrac{P(\\text{\"happy\" } \\cap \\text{Positive})}{P(\\text{\"Positive\"})}$\n",
    "\n",
    "Agora nós temos a equação para encontrar a **probabilidade condicional** de um tweet conter a palavra \"**happy**\" sabendo que ele é \"**Positive**\".\n",
    "\n",
    "### 2.1.3 Derivando o teorema de Bayes\n",
    "Como temos as duas equações acima, podemos finalmente **derivar o teorema de Bayes**! Pausa para uma rápida pesquisa do que significa **derivar** em Matemática:\n",
    "* 4. (Matemática) Ação de estimar, mensurar ou calcular a derivada de\n",
    "\n",
    "Vamos portanto combinar as equações:\n",
    "1. perceba que as intersecções representam a mesma quantidade e condições independente da ordem;\n",
    "2. sabendo disso, podemos **descartar as intersecções**;\n",
    "3. realizando manipulações algébricas, podemos chegar na equação seguinte:\n",
    "\n",
    "$P(Positive|\\text{\"happy\"}) = P(\\text{\"happy\"}|Positive) \\times \\dfrac{P(Positive)}{P(\\text{\"happy\"})}$\n",
    "\n",
    "Pronto! Com base nas duas equações mostradas, pudemos **criar uma equação** que expressa o teorema de Bayes para o contexto de análise do sentimento. Vamos analisar a equação criada:\n",
    "1. $P(Positive|\\text{\"happy\"}) = $ significa \"probabilidade de **X** dado que **Y** ocorreu é igual a...\n",
    "2. $P(\\text{\"happy\"}|Positive)$ \"probabilidade de **Y** dado que **X** ocorreu...\n",
    "3. $\\times \\dfrac{P(Positive)}{P(\\text{\"happy\"})}$ \"vezes a razão da probabilidade de **X** sobre a probabilidade de **Y**.\n",
    "\n",
    "Ou seja...\n",
    "$P(X|Y) = P(Y|X) \\times \\dfrac{P(X)}{P(Y)}$. Essa é a formulação básica do teorema de Bayes!\n",
    "\n",
    "\n",
    "#### Qual a probabilidade do tweet 'happy to learn math in NLP' ser classificado como Positivo, dadas as seguintes informações?\n",
    "* Positivos = 40%\n",
    "* 'happy' = 13%\n",
    "* Positivos + 'happy' = 25%\n",
    "\n",
    "$P(Positivo|\\text{'happy'}) = P(\\text{'happy'}|Positivo) \\times \\dfrac{P(Positivo)}{P(\\text{'happy'})}$\n",
    "\n",
    "Vamos realizar uma operação aritmética com $P(\\text{'happy'}|Positivo)$ e sua multiplicação pela razão de $\\dfrac{P(Positivo)}{P(\\text{'happy'})}$\n",
    "\n",
    "Ou seja: $\\dfrac{P(\\text{'happy'}|Positivo) \\times P(Positivo)}{P(\\text{'happy'})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substituindo os valores dados acima: $\\dfrac{\\text{25%} \\times \\text{40%}}{\\text{13%}} \\approx 0.77$ \n",
    "\n",
    "Ou seja, a probabilidade do tweet 'happy to learn math in NLP' de ser classificado como Positivo é de 77%.\n",
    "\n",
    "E o mais legal é que o teorema de Bayes pode ser utilizado em diversas aplicações, em diversos momentos de sua vida e para propósitos muito diversos. **Ele evita ambiguidades que o nosso cérebro comete, pois não somos bons estaticistas**. A estatística pode não ser **nada intuitiva** para o ser humano. Portanto, é importante não confiarmos totalmente em nossos insights sobre algum contexto probabilístico.\n",
    "\n",
    "O teorema de Bayes só funcionará para calcular a probabilidade de **X dado Y** se já soubermos a probabilidade de **Y dado X**, e para chegar a esse resultado podemos calcular a **probabilidade condicional**, como fizemos no primeiro e segundo casos da primeira sessão desse guia.\n",
    "\n",
    "Pronto para utilizar o teorema de Bayes (Baye's rule) para criar diversas aplicações de NLP?\n",
    "\n",
    "No próximo guia, estudaremos o algoritmo **Naive Bayes**, um classificador probabilístico simples que aplica o **teorema de Bayes** e que supõe **independência entre os preditores**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
