{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Laplacian Smoothing\n",
    "**Laplacian Smoothing** é uma das estratégias utilizadas para evitar que as probabilidades sejam \"0\".\n",
    "\n",
    "Realizar o \"Smoothing\" da probabilidade significa que estamos utilizando uma fórmula um pouco diferente da original, vamos comparar.\n",
    "\n",
    "A expressão utilizada para calcular a probabilidade condicional de uma **palavra**, dada sua **classe**, é igual à **frequência** da **palavra** no corpus ($w_i$, class) dividida pelo número de **palavras no corpus** ($N_{class}$).\n",
    "\n",
    "**Original**:\n",
    "$P(w_i|class) = \\dfrac{freq(w_i, class)}{N_{class}}$\n",
    "\n",
    "**Laplacian Smoothing**:\n",
    "$P(w_i|class) = \\dfrac{freq(w_i, class) + 1}{N_{class} + V}$\n",
    "\n",
    "Na fórmula com Smoothing, repare que foi adicionado o número \"**1**\" no numerador, isso evita que a probabilidade seja zero. Também foi adicionado o termo \"**V**\" no demoninador, que é o número de palavras únicas a serem normalizadas. Todas as probabilidades em cada coluna serão somadas a um. Isso é chamado **Laplacian Smoothing**.\n",
    "\n",
    "Como podemos calcular o número de palavras únicas no vocabulário? É basicamente somar o número de palavras, cada uma como sendo única, sem realizar a soma de frequências.\n",
    "\n",
    "<img src=\"images\\smoothing.png\" width=55%>\n",
    "\n",
    "Perceba que o número de palavras únicas, nas duas colunas, é 8 pois existem **8 palavras diferentes**. É então realizado o cálculo da probabilidade para cada palavra com o **Laplacian Smoothing**, como no exemplo acima. Perceba como a palavra **because** não possui mais probabilidade zero, e perceba também como a soma das probabilidades ainda é \"**1**\".\n",
    "\n",
    "<img src=\"images\\smoothing1.png\" width=20%>\n",
    "\n",
    "### 2.3.1 Categorias sentimentais e verossimilhança\n",
    "As palavras podem possuir diversos \"tons\" de significados, e também de emoções, porém para nossos propósitos, serão consideradas apenas três categorias: **neutro, positivo** e **negativo**. E as probabilidades condicionais podem classificar com sucesso uma palavra dentre uma das três categorias.\n",
    "\n",
    "Para estimar a categoria, podemos realizar o cálculo abaixo: a probabilidade de todas as palavras Positivas **dividido** pela probabilidade de todas as palavras Negativas.\n",
    "\n",
    "$ratio(w_i) = \\dfrac{P(w_i | Pos)}{P(w_i | Neg)}$\n",
    "\n",
    "Vamos relembrar a tabela com as probabilidades condicionais de cada palavra e realizar o cálculo dessa **razão**:\n",
    "<img src=\"images/naive bayes tabela probabilidade4.png\" width=50%>\n",
    "\n",
    "* Nas palavras normalmente consideradas **Positivas**, a razão (_ratio_) resultou em **maior do que um**;\n",
    "* Nas **Neutras**, resultou em **igual a um**;\n",
    "* E nas **Negativas**, resultou em **menor do que um**.\n",
    "\n",
    "Algo interessante é que **quanto maior a razão**, **mais positivo**. O mesmo para as **negativas**.\n",
    "\n",
    "As **razões** acima são essenciais para o classificador Naive Bayes quando se trata de **classificação binária**. Vamos a um exemplo.\n",
    "\n",
    "Acabamos de ver como classificar o produto como **positivo** se as razões correspondentes de cada palavra do tweet forem **maiores que um**? E, também, **negativo** se menor do que um. Isso se chama **verossimilhança**.\n",
    "\n",
    "Se nós obtemos o **ratio** entre tweets Pos e Neg, temos na verdade algo chamado **prior ratio**. Porém esse conceito só é importante em **_datasets_ desbalanceados**, o que não é o nosso caso."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
